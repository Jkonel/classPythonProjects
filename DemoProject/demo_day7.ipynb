{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitpytorchconda5ca5c260ccf143f3a30a360446f5e1fa",
   "display_name": "Python 3.8.1 64-bit ('pytorch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_reptile\n",
    "\n",
    "my_rep = my_reptile.my_reptile()\n",
    "\n",
    "rang = 95+1\n",
    "\n",
    "for i in range(1,rang):\n",
    "    url = 'http://search.jumei.com/?filter=0-11-{0}&search=%E5%8F%A3%E7%BA%A2&from=search_toplist_%E5%8F%A3%E7%BA%A2_word_pos_6&cat='.format(i)\n",
    "    name = 'page_1_{0}.html'.format(i)\n",
    "    my_rep.page_download(url,name)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 子页面读取\n",
    "import my_reptile\n",
    "from lxml import etree\n",
    "my_rep = my_reptile.my_reptile()\n",
    "import time\n",
    "\n",
    "indexs = 0\n",
    "for i in range(1,6):\n",
    "    indexs = 0\n",
    "\n",
    "    name = 'page_1_{0}.html'.format(i)\n",
    "    path_name = './date_{0}'.format(my_rep.text_time()[1])\n",
    "    html = etree.parse(path_name+'/'+name, parser = etree.HTMLParser(encoding = 'utf-8'))\n",
    "    \n",
    "    items = html.xpath('//div[@class = \"products_wrap\"]/ul/li')\n",
    "    #-------------------文件解析------------------#\n",
    "    for item in items:\n",
    "        inside = item.xpath('.//div[@class = \"s_l_name\"]/a/@href')\n",
    "        if inside:\n",
    "            inside = inside[0]\n",
    "        else:\n",
    "            inside = None\n",
    "        print(inside)\n",
    "\n",
    "        name2 = 'page_2_{0}_{1}.html'.format(i,indexs)\n",
    "        time.sleep(1)\n",
    "        my_rep.page_download(inside,name2)\n",
    "        indexs += 1\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------文件读取------------------#\n",
    "data = []\n",
    "\n",
    "for i in range(1,96):\n",
    "    html = etree.parse(f'./htmls/data_{i}.html',parser = etree.HTMLParser(encoding='utf-8'))\n",
    "    print(f'./htmls/data_{i}.html')\n",
    "    items = html.xpath('//div[@class = \"products_wrap\"]/ul/li')\n",
    "    #-------------------文件解析------------------#\n",
    "    for item in items:\n",
    "        dic = {}\n",
    "        price = item.xpath('.//div[@class = \"s_l_view_bg\"]/div[@class = \"search_list_price\"]/span/text()')\n",
    "        title = item.xpath('.//div[@class = \"s_l_name\"]/a/text()')\n",
    "        #inside = item.xpath('.//div[@class = \"s_l_name\"]/a/@href')\n",
    "        #shop = item.xpath('./div[@class=\"p-shop\"]/span/a/text()')\n",
    "        #comment = item.xpath('./div[@class=\"p-commit\"]/strong/a')\n",
    "\n",
    "        if price:\n",
    "            price = cpmlexStr2nums(price[0])\n",
    "        else:\n",
    "            price =None\n",
    "        if title:\n",
    "            title = ''.join(''.join(re.findall(r'[\\d\\w\\S]+',title[0])))\n",
    "        else:\n",
    "            title = None\n",
    "    \n",
    "        dic['price'] = price\n",
    "        dic['title'] = title\n",
    "        data.append(dic)\n",
    "\n",
    "#---------------文件保存----------------#\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('./htmls/data.csv',index = 0,na_rep = 'NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_reptile\n",
    "from lxml import etree\n",
    "my_rep = my_reptile.my_reptile()\n",
    "import time\n",
    "\n",
    "data = [{'test1':'123'}]\n",
    "\n",
    "my_rep.csv_save(data,'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(np.random.rand())\n",
    "print(np.random.randn(4,5))\n",
    "print(np.random.randint(5,8))\n",
    "\n",
    "\n",
    "print(np.arange(0,20).reshape(2,10))\n",
    "\n",
    "\n",
    "print(np.empty((2.4)))\n",
    "print(np.zeros((5,2)))\n",
    "print(np.ones((2,5)))\n",
    "\n",
    "\n",
    "print(np.eye(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.62268788  0.26620107  1.41087325 -1.44204127  0.47273715 -0.94655893\n   1.67034365  0.62907934 -1.74602011  0.28553442 -1.49561347 -0.39052773\n  -0.8515046   0.01388708  0.68418158  1.67768255 -0.90527474  0.28820529\n  -0.90744967 -0.68346676]]\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n[]\n"
    }
   ],
   "source": [
    "arr00 = np.random.randn(1,20)\n",
    "arr01 = np.arange(20)\n",
    "\n",
    "\n",
    "arr02 = arr00[(arr00>5)&(arr00<8)]\n",
    "\n",
    "print(arr00)\n",
    "print(arr01)\n",
    "print(arr02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}