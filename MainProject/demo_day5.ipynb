{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitpytorchconda5ca5c260ccf143f3a30a360446f5e1fa",
   "display_name": "Python 3.8.1 64-bit ('pytorch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY5\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 正则表达式测试2\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "strings = '152.256'\n",
    "\n",
    "#res = re.findall(r'industr(?:y|ies)',strings)   #非获取匹配，不进行存储供以后使用。\n",
    "#res = re.findall(r'industr(y|ies)',strings)     #捕获匹配，同时匹配industry或industries，但捕获y或ies。\n",
    "res = re.findall(r'\\d(?:\\d|\\.)+',strings)       # <+> 匹配前面的子表达式一次或多次\n",
    "#res = re.findall(r'\\d(?:\\d|\\.)+?',strings)       # <+?> 非贪婪模式，尽可能少的匹配\n",
    "#res = re.findall(r'\\d(?:\\d|\\.\\d)*',strings)       #<*> 匹配前面的子表达式零次或多次\n",
    "\n",
    "print(res)\n",
    "print(float(res[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. XML"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# 网络头1\n",
    "header = {'User-Agent':' Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36','Referer':' http://baidu.com.com/',}\n",
    "\n",
    "#网络头2\n",
    "headers = {'Referer': 'https://space.bilibili.com/546195/fans/follow',\n",
    "    'Sec-Fetch-Mode': 'no-cors',\n",
    "    'User-Agent': ' Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "    }\n",
    "\n",
    "#########网页下载，存储##########\n",
    "nums = 23\n",
    "for i in range(1,nums+1):\n",
    "    url = f'http://search.jumei.com/?filter=0-11-{i}&search=%E9%98%B2%E6%99%92%E9%9C%9C&from=&cat='\n",
    "    file_name = f'.//read_files_{i}.html'\n",
    "    respond = requests.get(url,headers) \n",
    "    if respond.status_code == 200:\n",
    "        with open(file_name,'w',encoding='utf-8') as fp:\n",
    "            fp.write(respond.text)\n",
    "    print(respond.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########网页内容读取#############\n",
    "nums = 23\n",
    "for i in range(1,nums+1):\n",
    "    file_name = f'.//read_files_{i}.html'\n",
    "    with open(file_name,'r',encoding='utf-8') as fp:\n",
    "        content += fp.read()\n",
    "with open(r'./all_data/data.html','w',encoding='utf-8') as fp:\n",
    "    fp.write(content)\n",
    "#print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. xml解析内容属性"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html  = etree.parse('data.xml')\n",
    "book = html.xpath('/bookstore/book')\n",
    "#print(len(book))\n",
    "for b in book:\n",
    "    #title = b.xpath('title')[0].text\n",
    "    title = b.xpath('./title/@lang')\n",
    "    print(title)\n",
    "\n",
    "\n",
    "#ts = html.xpath('//title/@lang')\n",
    "#print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. xml筛选节点"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html  = etree.parse('data.xml')\n",
    "\n",
    "book_web = html.xpath('//book[@category = \"web\"]')\n",
    "for i in book_web:\n",
    "    tit = i[0].text\n",
    "    print(tit)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. xml转字典列表"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html  = etree.parse('data.xml')\n",
    "\n",
    "list_book =[]\n",
    "\n",
    "books = html.xpath('//book')\n",
    "print(books)\n",
    "for book in books:\n",
    "    b={}\n",
    "    t = book.xpath('./title/text()')\n",
    "    auth = book.xpath('./author/text()')\n",
    "    price = book.xpath('./price/text()')\n",
    "\n",
    "    if t:\n",
    "        b['title'] = t[0]\n",
    "    else:\n",
    "        b['title'] = None\n",
    "\n",
    "    if auth:\n",
    "        b['author'] = auth[0]\n",
    "    else:\n",
    "        b['author'] = None\n",
    "    \n",
    "    if price:\n",
    "        b['price'] = price[0]\n",
    "    else:\n",
    "        b['price'] = None\n",
    "\n",
    "    list_book.append(b)\n",
    "\n",
    "#print(list_book)\n",
    "list_book\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. 实战"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "\n",
    "# str转float方法\n",
    "def cpmlexStr2nums(str):\n",
    "    result = re.findall(r'\\d(?:\\d|\\.)+',str)\n",
    "    return float(result[0])\n",
    "#------------------------#\n",
    "my_parser = etree.HTMLParser(encoding='utf-8')\n",
    "html  = etree.parse('read_files_1.html',parser=my_parser)\n",
    "\n",
    "## xpath //:选取内容为总文件所匹配的所有标签\n",
    "##      .//:选取内容为当前节点文件所匹配的所有标签\n",
    "\n",
    "items_1 = html.xpath('//div[@id = \"container\"]/div[@id = \"body\"]/div[@id = \"search_result_wrap\"]/div[@id = \"search_list_wrap\"]/div[@class = \"products_wrap\"]/ul/li')\n",
    "\n",
    "data = []\n",
    "for item in items_1:\n",
    "    dic ={}\n",
    "    price = item.xpath('.//div[@class = \"search_list_price\"]/span/text()')\n",
    "    old_price = item.xpath('.//div[@class = \"search_list_price\"]/del/text()')\n",
    "    \n",
    "    if price:\n",
    "        dic['price'] = cpmlexStr2nums(price[0])\n",
    "    else:\n",
    "        dic['price'] = None\n",
    "    if old_price:\n",
    "        dic['old_price'] = cpmlexStr2nums(old_price[0])\n",
    "    else:\n",
    "        dic['old_price'] = None\n",
    "    data.append(dic)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CSV"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_book)\n",
    "\n",
    "df.to_csv('./data.csv',index = 0,na_rep = 'NA')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 实战作业"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# str转float方法\n",
    "def cpmlexStr2nums(str):\n",
    "    result = re.findall(r'\\d(?:\\d|\\.)+',str)\n",
    "    return float(result[0])\n",
    "\n",
    "#-----------------网页爬虫------------------#\n",
    "headers = {'user-agent':'Mozilla/5.0'}\n",
    "url = f'https://search.jd.com/Search?keyword=ps4&enc=utf-8&wq=ps4&pvid=d33c75596e874f27957208ea177ad7c3'\n",
    "\n",
    "respond = requests.get(url,headers = headers) \n",
    "if respond.status_code == 200:\n",
    "     with open(f'.//data.html','w',encoding='utf-8') as fp:\n",
    "         fp.write(respond.text)\n",
    "\n",
    "#-------------------文件读取--------------------#\n",
    "#html  = etree.parse('data_1.html',parser = etree.HTMLParser(encoding='utf-8'))\n",
    "html  = etree.parse('data.html',parser = etree.HTMLParser(encoding='utf-8'))\n",
    "#print(html)\n",
    "\n",
    "items = html.xpath('//ul[contains(@class,\"gl-warp clearfix\")]/li/div[@class=\"gl-i-wrap\"]')\n",
    "\n",
    "#-------------------文件解析------------------#\n",
    "data = []\n",
    "for item in items:\n",
    "    dic ={}\n",
    "    price = item.xpath('./div[@class=\"p-price\"]/strong/i/text()')\n",
    "    title = item.xpath('./div[@class=\"p-name p-name-type-2\"]/a/em/text()')\n",
    "    shop = item.xpath('./div[@class=\"p-shop\"]/span/a/text()')\n",
    "    #comment = item.xpath('./div[@class=\"p-commit\"]/strong/a')\n",
    "\n",
    "    if price:\n",
    "        price = cpmlexStr2nums(price[0])\n",
    "    else:\n",
    "        price =None\n",
    "    if title:\n",
    "        title = ''.join(title)\n",
    "    else:\n",
    "        title =None\n",
    "    if shop:\n",
    "        shop = ''.join(shop)\n",
    "    else:\n",
    "        shop = None\n",
    "    \n",
    "    dic['price'] = price\n",
    "    dic['title'] = title\n",
    "    dic['shop'] = shop\n",
    "    data.append(dic)\n",
    "\n",
    "#---------------文件保存----------------#\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('./data.csv',index = 0,na_rep = 'NA')\n",
    ""
   ]
  }
 ]
}